{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPKXBIm/8Lz+KkmCVSptiQm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2t3Plk1WgtG2","executionInfo":{"status":"ok","timestamp":1716448294289,"user_tz":360,"elapsed":244,"user":{"displayName":"Carlos Lopez","userId":"16322779306794316926"}},"outputId":"2ed076e8-3dd0-409c-cf05-7812757171e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K4ZggKtlg36A","executionInfo":{"status":"ok","timestamp":1716448296683,"user_tz":360,"elapsed":196,"user":{"displayName":"Carlos Lopez","userId":"16322779306794316926"}},"outputId":"639d1183-f5cd-4175-d6f8-dd61d16c306a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu May 23 07:11:36 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   51C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["!pip install nvcc4jupyter\n","%load_ext nvcc4jupyter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y_7KIb7BweuW","executionInfo":{"status":"ok","timestamp":1716448308245,"user_tz":360,"elapsed":9572,"user":{"displayName":"Carlos Lopez","userId":"16322779306794316926"}},"outputId":"3b90ba2f-7293-4fe3-a3ee-d4d9307e2636"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting nvcc4jupyter\n","  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n","Installing collected packages: nvcc4jupyter\n","Successfully installed nvcc4jupyter-1.2.1\n","Detected platform \"Colab\". Running its setup...\n","Source files will be saved in \"/tmp/tmpdnlyl_1x\".\n"]}]},{"cell_type":"code","source":["%%cuda\n","#include <cstdio>\n","#include <cuda_runtime.h>\n","//This fctn will run on the device\n","__global__ void helloWorldKernel(){\n","    printf(\"Hello World!\\n\");\n","}\n","int main(){\n","    //here we launch the kernel\n","    helloWorldKernel<<<1,1>>>(); //DimGrid is 1 and DimBlock is 1\n","    //wait for the kernel to finish\n","    cudaDeviceSynchronize();\n","    return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"01SWE-wHwpTh","executionInfo":{"status":"ok","timestamp":1716448313975,"user_tz":360,"elapsed":4137,"user":{"displayName":"Carlos Lopez","userId":"16322779306794316926"}},"outputId":"e3b8004a-d55c-41ad-9aee-ed514e6f4dd8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello World!\n","\n"]}]},{"cell_type":"code","source":["%%cuda\n","#include <iostream>\n","#include <cuda_runtime.h>\n","__global__ void add(int *d_a, int *d_b, int *d_c, int n){\n","    int idx = threadIdx.x;\n","    /*if(i < n){\n","        d_c[idx] = d_a[idx] + d_c[idx];\n","    }*/\n","    //Now this is not good if we do not have enough threads\n","    //we will change it to a for loop\n","\n","    for(int i = idx; i < n; i += blockDim.x){\n","        d_c[i] = d_a[i] + d_b[i];\n","    }\n","}\n","\n","    //Now we are safe if we launch the kernel with n-1 or less threads\n","__host__\n","int main(){\n","        //we will set the constant and the host memory\n","        const int n = 12;\n","        int h_a[n], h_b[n], h_c[n]; // these are the host array variables\n","        //Initialize the arrays\n","        for(int i =1; i <=n; i++){\n","            h_a[i] = i;\n","            h_b[i] = i * 2;\n","        }\n","\n","        //Now we will work on the device memory\n","        int *d_a, *d_b, *d_c;\n","        cudaMalloc(&d_a, n * sizeof(int));\n","        cudaMalloc(&d_b, n*sizeof(int));\n","        cudaMalloc(&d_c, n * sizeof(int));\n","\n","        //copy from host to device\n","        cudaMemcpy(d_a, h_a, n * sizeof(int), cudaMemcpyHostToDevice);\n","        cudaMemcpy(d_b, h_b, n*sizeof(int), cudaMemcpyHostToDevice);\n","        cudaDeviceSynchronize();\n","        //Launch the kernel\n","        add<<<1,n-1>>>(d_a, d_b, d_c, n);\n","        cudaDeviceSynchronize();\n","        //Now after the execution of the kernel, we have to copy memory back to the device\n","        cudaMemcpy(h_c, d_c, n*sizeof(int), cudaMemcpyDeviceToHost);\n","        cudaDeviceSynchronize();\n","        //Print the results\n","        for(int i =0; i < n; i++){\n","            std::cout << h_c[i] << \" \";\n","        }\n","        //now we have to free the allocated memeory\n","        cudaFree(d_a);\n","        cudaFree(d_b);\n","        cudaFree(d_c);\n","        return 0;\n","        }"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yPKbsq1g3twt","executionInfo":{"status":"ok","timestamp":1716448522258,"user_tz":360,"elapsed":2225,"user":{"displayName":"Carlos Lopez","userId":"16322779306794316926"}},"outputId":"3ba1c16e-63b7-4c52-d39d-2475de6b6154"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["12 3 6 9 12 15 18 21 24 27 30 33 \n"]}]}]}